{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e907fec",
   "metadata": {},
   "source": [
    "# CS Network Science — Project 1: *From Bipartite to Insights*  \n",
    "**Starter Notebook (Created 2025-08-29)**  \n",
    "Use this scaffold to complete your analysis. Read each markdown cell carefully, then write code in the following cell.\n",
    "\n",
    "**Rules**\n",
    "- You may (and should) use a coding assistant (ChatGPT, Gemini, etc.).\n",
    "- Cite your prompts and summarize what you accepted/changed in the **LLM Usage Log** section.\n",
    "- Set random seeds for reproducibility.\n",
    "- Keep your code readable and modular.\n",
    "\n",
    "**Grading**: Points are shown next to each task. Total = **100 points**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8bbbb",
   "metadata": {},
   "source": [
    "## Dataset Selection (no points)\n",
    "Pick **one** dataset slice so each submission is unique. A few ideas:\n",
    "- **MovieLens** (users–movies): ratings subset such as small (100k).\n",
    "- **Citi Bike NYC** (trips–stations): one month of trips.\n",
    "- **Stack Overflow** (posts–tags): a CSV of post–tag pairs.\n",
    "- **OpenFlights** (airline–airport or airport–route).\n",
    "\n",
    "You may choose another public bipartite source with instructor approval. Keep it small for this first project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e002ac",
   "metadata": {},
   "source": [
    "### Task 1 — Imports & Environment *(5 points)*\n",
    "Write code to:\n",
    "1) Import standard libraries (`pandas`, `numpy`, `matplotlib`, `networkx`, and any community package you choose).\n",
    "2) Set a global random seed.\n",
    "3) Configure matplotlib for inline plots with a reasonable default figure size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02605e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 1 — Imports & Environment (5 pts)\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Optional community detection package (e.g., python-louvain)\n",
    "# from community import community_louvain\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Plot defaults\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "plt.rcParams['axes.grid'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9b1e7",
   "metadata": {},
   "source": [
    "### Task 2 — Load a Raw Slice of Your Dataset *(10 points)*\n",
    "Write code to:\n",
    "- Load your raw data from a local file or URL.\n",
    "- Display the **shape** and a **5-row preview**.\n",
    "- Briefly print what's in each column (types or a short description).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 2 — Load data (10 pts)\n",
    "# Hints:\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "# print(df.shape)\n",
    "# display(df.head())\n",
    "# print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e80b5b",
   "metadata": {},
   "source": [
    "### Task 3 — Minimal Cleaning *(5 points)*\n",
    "Write code to perform **lightweight cleaning** as appropriate for your dataset, such as:\n",
    "- Dropping rows with missing critical IDs\n",
    "- Filtering out extremely rare items/tags or implausible records\n",
    "- Keeping a focused time window or category subset\n",
    "Print the new shape and a short note of what you did.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b94f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 3 — Minimal Cleaning (5 pts)\n",
    "# Example:\n",
    "# df = df.dropna(subset=['user_id','item_id'])\n",
    "# df = df[df['timestamp'].between('2021-07-01','2021-07-31')]\n",
    "# print('After cleaning:', df.shape)\n",
    "# print('Cleaning notes: ...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aca1b8",
   "metadata": {},
   "source": [
    "### Task 4 — Build a Bipartite Graph *(10 points)*\n",
    "Define which side is **Top** (e.g., users) and which is **Bottom** (e.g., items). Then:\n",
    "- Construct a bipartite graph `B` using `networkx`.\n",
    "- Ensure each node has an attribute `bipartite` = 0 (Top) or 1 (Bottom).\n",
    "- Print node/edge counts for sanity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 4 — Build Bipartite Graph (10 pts)\n",
    "# Example scaffold (rename columns to match your data):\n",
    "# top_col = 'user_id'\n",
    "# bottom_col = 'item_id'\n",
    "# B = nx.Graph()\n",
    "# B.add_nodes_from(df[top_col].unique(), bipartite=0)\n",
    "# B.add_nodes_from(df[bottom_col].unique(), bipartite=1)\n",
    "# edges = list(zip(df[top_col], df[bottom_col]))\n",
    "# B.add_edges_from(edges)\n",
    "# print('Bipartite nodes:', B.number_of_nodes(), 'edges:', B.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87e768",
   "metadata": {},
   "source": [
    "### Task 5 — One-Mode Projection *(10 points)*\n",
    "Create **one** projection (e.g., Bottom–Bottom / item–item), where edge weights represent shared neighbors.\n",
    "- Build the projected graph `G`.\n",
    "- Keep only the **largest connected component** of `G`.\n",
    "- Print node/edge counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 5 — One-Mode Projection (10 pts)\n",
    "# Hints: networkx.algorithms.bipartite has projection helpers, or compute co-occurrence manually.\n",
    "# from networkx.algorithms import bipartite\n",
    "# bottom_nodes = [n for n,d in B.nodes(data=True) if d.get('bipartite')==1]\n",
    "# G = bipartite.weighted_projected_graph(B, bottom_nodes)\n",
    "# largest_cc = max(nx.connected_components(G), key=len)\n",
    "# G = G.subgraph(largest_cc).copy()\n",
    "# print('Projected G:', G.number_of_nodes(), 'nodes /', G.number_of_edges(), 'edges')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c231894",
   "metadata": {},
   "source": [
    "### Task 6 — Degree & Weighted Degree Summary *(8 points)*\n",
    "Compute and display:\n",
    "- Top 10 nodes by degree\n",
    "- Top 10 nodes by **weighted** degree (sum of incident weights)\n",
    "Show a simple bar plot of the **degree distribution** (or weighted degree distribution).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 6 — Degree summaries (8 pts)\n",
    "# degrees = dict(G.degree())\n",
    "# w_degrees = dict(G.degree(weight='weight'))\n",
    "# ... sort, print top 10, and plot a histogram ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20607911",
   "metadata": {},
   "source": [
    "### Task 7 — Giant Component Size, Average Path Length, Diameter *(10 points)*\n",
    "Compute on the **largest connected component** of `G`:\n",
    "- Size (nodes, edges)\n",
    "- Average shortest path length (if graph is not too large; otherwise sample)\n",
    "- Diameter (exact or approximate)\n",
    "Print the results with brief comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 7 — GC metrics (10 pts)\n",
    "# Hints:\n",
    "# H = G  # if already GC\n",
    "# n_nodes, n_edges = H.number_of_nodes(), H.number_of_edges()\n",
    "# try:\n",
    "#     aspl = nx.average_shortest_path_length(H)\n",
    "# except Exception:\n",
    "#     aspl = None\n",
    "# # For diameter, consider eccentricity or approximate methods\n",
    "# # diam = nx.diameter(H)  # may be expensive\n",
    "# print({'nodes': n_nodes, 'edges': n_edges, 'avg_path_length': aspl, 'diameter': '...'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a4cf7",
   "metadata": {},
   "source": [
    "### Task 8 — Clustering Coefficients *(6 points)*\n",
    "Compute the **global clustering coefficient** and show the **distribution of local clustering** values (histogram or box plot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261102a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 8 — Clustering (6 pts)\n",
    "# global_c = nx.transitivity(G)\n",
    "# local_c = nx.clustering(G, weight=None)\n",
    "# ... plot distribution of local_c.values() ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a434b",
   "metadata": {},
   "source": [
    "### Task 9 — Assortativity *(6 points)*\n",
    "Compute **degree assortativity** for `G`.\n",
    "If you have a categorical attribute (e.g., genre, borough, airline), compute assortativity by that attribute and comment briefly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 9 — Assortativity (6 pts)\n",
    "# deg_assort = nx.degree_assortativity_coefficient(G)\n",
    "# print('Degree assortativity:', deg_assort)\n",
    "# # If attribute exists on nodes:\n",
    "# # attr_assort = nx.attribute_assortativity_coefficient(G, 'your_attr')\n",
    "# # print('Attribute assortativity:', attr_assort)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011bcf2",
   "metadata": {},
   "source": [
    "### Task 10 — Community Detection & Interpretation *(10 points)*\n",
    "Run a community detection algorithm (e.g., Louvain). Then:\n",
    "- Report the number of communities and sizes of the top 3.\n",
    "- Compute modularity if available.\n",
    "- Write **one sentence per top community** interpreting what it represents (based on metadata you have).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec50fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 10 — Communities (10 pts)\n",
    "# Example using python-louvain if installed:\n",
    "# import community as community_louvain\n",
    "# partition = community_louvain.best_partition(G, random_state=SEED, weight='weight')\n",
    "# # Count sizes\n",
    "# from collections import Counter\n",
    "# sizes = Counter(partition.values())\n",
    "# print('Communities:', len(sizes))\n",
    "# print('Top 3 sizes:', sizes.most_common(3))\n",
    "# # (Optional) compute modularity\n",
    "# # modularity = community_louvain.modularity(partition, G, weight='weight')\n",
    "# # print('Modularity:', modularity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8dca8",
   "metadata": {},
   "source": [
    "### Task 11 — Five Random Shortest Paths *(6 points)*\n",
    "Randomly sample **five** node pairs from the largest component and report:\n",
    "- The path length, and the node sequence for each pair.\n",
    "If disconnected (shouldn’t be on GC), resample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 11 — Five random shortest paths (6 pts)\n",
    "# import random\n",
    "# nodes = list(G.nodes())\n",
    "# for i in range(5):\n",
    "#     s, t = random.sample(nodes, 2)\n",
    "#     try:\n",
    "#         p = nx.shortest_path(G, s, t, weight=None)\n",
    "#         print(f'Pair {i+1}: {s} -> {t} | length={len(p)-1} | path={p}')\n",
    "#     except nx.NetworkXNoPath:\n",
    "#         print('No path found; resample if needed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f1b15",
   "metadata": {},
   "source": [
    "### Task 12 — Small Subgraph Visualization *(8 points)*\n",
    "Create a visualization of a **small subgraph**:\n",
    "- Select the top 50 nodes by **weighted degree** (or degree if unweighted).\n",
    "- Draw with a spring layout; label the top 10 nodes.\n",
    "- Include a legend or caption explaining what is shown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Task 12 — Visualization (8 pts)\n",
    "# # Compute weighted degree and select top nodes\n",
    "# wdeg = dict(G.degree(weight='weight'))\n",
    "# top_nodes = [n for n,_ in sorted(wdeg.items(), key=lambda x: x[1], reverse=True)[:50]]\n",
    "# S = G.subgraph(top_nodes).copy()\n",
    "# pos = nx.spring_layout(S, seed=SEED)\n",
    "# nx.draw_networkx(S, pos=pos, with_labels=False, node_size=50)\n",
    "# # Label top 10\n",
    "# for n,_ in list(sorted(wdeg.items(), key=lambda x: x[1], reverse=True))[:10]:\n",
    "#     if n in S:\n",
    "#         x,y = pos[n]\n",
    "#         plt.text(x, y, str(n), fontsize=8)\n",
    "# plt.title('Subgraph of Top-Weighted-Degree Nodes')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073cbb3c",
   "metadata": {},
   "source": [
    "### Task 13 — (Optional) Weighted vs. Unweighted Comparison *(up to 5 bonus points)*\n",
    "Compare one metric (clustering, assortativity, or community modularity) under weighted vs. unweighted assumptions. Briefly comment on the difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Optional): Implement Task 13 — Weighted vs. Unweighted (up to 5 bonus pts)\n",
    "# # Example: compare clustering with and without weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c27e9e",
   "metadata": {},
   "source": [
    "### Task 14 — (Optional) Robustness Experiment *(up to 5 bonus points)*\n",
    "Simulate node removal:\n",
    "- Random removal in steps; plot giant-component size vs. fraction removed.\n",
    "- Targeted removal by decreasing weighted degree; plot on same figure.\n",
    "Briefly compare the curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5114d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Optional): Implement Task 14 — Robustness (up to 5 bonus pts)\n",
    "# # Outline:\n",
    "# # for each fraction f in np.linspace(0,1,...) remove nodes and measure GC size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b30a60",
   "metadata": {},
   "source": [
    "### Task 15 — Mini Write-up *(10 points)*\n",
    "In a short markdown cell, summarize:\n",
    "- Structure (density, paths, clustering) in one paragraph.\n",
    "- Communities (count, themes) in one paragraph.\n",
    "- One *surprising* finding in 1–2 sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883f056",
   "metadata": {},
   "source": [
    "_Write your mini write-up here. (10 pts)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd92940a",
   "metadata": {},
   "source": [
    "### Task 16 — LLM Usage Log *(5 points)*\n",
    "Paste your **2–3 most helpful prompts** to the LLM and briefly state what you accepted vs. modified. Two or three bullet points are fine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafa954",
   "metadata": {},
   "source": [
    "_Add your LLM usage notes here. (5 pts)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
